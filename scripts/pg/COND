from itertools import product

CONFIGS = [
  # Represents 64 B records, 2816 bytes per page +/- (5 * 2 * 64) bytes
  {
    "goal": 44,
    "epsilon": 5,
    "record_size_bytes": 64,
  },
  # Represents 1024 B records, 2048 bytes per page +/- (0.5 * 2 * 1024) bytes
  {
    "goal": 2,
    "epsilon": 0.5,
    "record_size_bytes": 1024,
  },
]

CUSTOM_DATASETS = [
  {"name": "amzn", "file": "amazon_reviews.txt", "workload": "long_scan-amzn.yml"},
  {"name": "osm", "file": "osm_ny.txt", "workload": "long_scan-osm.yml"},
]

run_experiment_group(
  name="long_scan",
  run="./run.sh",
  experiments=[
    ExperimentInstance(
      name="long_scan-uniform-{record_size_bytes}-{goal}-{epsilon}-{segs}".format(segs=segs, **config),
      options={
        "records_per_page_goal": config["goal"],
        "records_per_page_epsilon": config["epsilon"],
        "record_size_bytes": config["record_size_bytes"],
        "workload_config": "workloads/20M/long_scan.yml",
        "checkpoint_name": "uniform-{record_size_bytes}-{goal}-{epsilon}-{segs}".format(segs=segs, **config),
        "disable_segments": (segs == "pages"),
      },
    )
    for config, segs in product(CONFIGS, ["segs", "pages"])
  ] + [
    ExperimentInstance(
      name="long_scan-{dataset}-{record_size_bytes}-{goal}-{epsilon}-{segs}".format(
        segs=segs,
        dataset=dataset["name"],
        **config,
      ),
      options={
        "records_per_page_goal": config["goal"],
        "records_per_page_epsilon": config["epsilon"],
        "record_size_bytes": config["record_size_bytes"],
        "workload_config": "workloads/20M/{}".format(dataset["workload"]),
        "custom_dataset": "'$TP_DATASET_PATH/{}'".format(dataset["file"]),
        "checkpoint_name": "{dataset}-{record_size_bytes}-{goal}-{epsilon}-{segs}".format(
          segs=segs,
          dataset=dataset["name"],
          **config,
        ),
        "disable_segments": (segs == "pages"),
      },
    )
    for config, segs, dataset in product(CONFIGS, ["segs", "pages"], CUSTOM_DATASETS)
  ],
  deps=[":preload"],
)

# Checkpoint set up tasks.

group(
  name="preload",
  deps=[
    ":preload-{dataset}-{record_size_bytes}-{goal}-{epsilon}-{segs}".format(dataset=dataset, segs=segs, **config)
    for config, dataset, segs in product(
      CONFIGS,
      ["uniform", *map(lambda d: d["name"], CUSTOM_DATASETS)],
      ["segs", "pages"],
    )
  ],
)

# Uniform dataset.
for config in CONFIGS:
  run_command(
    name="preload-uniform-{record_size_bytes}-{goal}-{epsilon}-segs".format(**config),
    run="./preload.sh "
      "--workload_config=workloads/20M/preload.yml "
      "--records_per_page_goal={goal} "
      "--records_per_page_epsilon={epsilon} "
      "--record_size_bytes={record_size_bytes} "
      "--checkpoint_name=uniform-{record_size_bytes}-{goal}-{epsilon}-segs "
      "--disable_segments=false".format(**config),
  )

  run_command(
    name="preload-uniform-{record_size_bytes}-{goal}-{epsilon}-pages".format(**config),
    run="./preload.sh "
      "--workload_config=workloads/20M/preload.yml "
      "--records_per_page_goal={goal} "
      "--records_per_page_epsilon={epsilon} "
      "--record_size_bytes={record_size_bytes} "
      "--checkpoint_name=uniform-{record_size_bytes}-{goal}-{epsilon}-pages "
      "--disable_segments=true".format(**config),
  )

# Custom datasets.
for config, dataset in product(CONFIGS, CUSTOM_DATASETS):
  run_command(
    name="preload-{dataset}-{record_size_bytes}-{goal}-{epsilon}-segs".format(
      dataset=dataset["name"],
      **config,
    ),
    run="./preload.sh "
      "--workload_config=workloads/20M/preload.yml "
      "--custom_dataset='$TP_DATASET_PATH/{dataset_file}' "
      "--records_per_page_goal={goal} "
      "--records_per_page_epsilon={epsilon} "
      "--record_size_bytes={record_size_bytes} "
      "--checkpoint_name={dataset}-{record_size_bytes}-{goal}-{epsilon}-segs "
      "--disable_segments=false".format(
        dataset=dataset["name"],
        dataset_file=dataset["file"],
        **config,
      ),
  )

  run_command(
    name="preload-{dataset}-{record_size_bytes}-{goal}-{epsilon}-pages".format(
      dataset=dataset["name"],
      **config,
    ),
    run="./preload.sh "
      "--workload_config=workloads/20M/preload.yml "
      "--custom_dataset='$TP_DATASET_PATH/{dataset_file}' "
      "--records_per_page_goal={goal} "
      "--records_per_page_epsilon={epsilon} "
      "--record_size_bytes={record_size_bytes} "
      "--checkpoint_name={dataset}-{record_size_bytes}-{goal}-{epsilon}-pages "
      "--disable_segments=true".format(
        dataset=dataset["name"],
        dataset_file=dataset["file"],
        **config,
      ),
  )

run_command(
  name="ssd_data",
  run="python3 process_fio.py",
  deps=[
    "//scripts/iochar/read:read_rand_sweep",
  ],
)
