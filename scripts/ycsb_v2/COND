from itertools import product

WORKLOADS = [
  "a", "b", "c", "d", "scan_only", "f",
]

DBS = [
  "pg_llsm",
  "rocksdb",
]

DISTRIBUTIONS = ["zipfian", "uniform"]

THREADS = [1, 2, 4, 8, 16]

CONFIGS = [
  {
    "name": "64B",
    "record_size_bytes": 64,

    # Used by LLSM.
    "llsm_page_fill_pct": 70,

    # Used by page-grouped LLSM.
    "records_per_page_goal": 45,
    "records_per_page_delta": 5,

    # Used by all DBs.
    # 408 MiB in total (2 x 64 MiB + 280 MiB, ~33% of the dataset)
    "memtable_mib": 64,
    "cache_mib": 280,

    # Used to configure the length of the workload.
    # These values are scaled up by the dataset size multiplier.
    "point_requests": 15000000,  # 15 million
    "scan_requests":  1000000,   # 1 million
  },
  {
    "name": "1024B",
    "record_size_bytes": 1024,

    # Used by LLSM.
    "llsm_page_fill_pct": 50,

    # Used by page-grouped LLSM.
    "records_per_page_goal": 2,
    "records_per_page_delta": 1,

    # Used by all DBs.
    # 3255 MiB in total ~33% of the dataset
    "memtable_mib": 510,
    "cache_mib": 2235,

    # Used to configure the length of the workload.
    # These values are scaled up by the dataset size multiplier.
    "point_requests": 7500000,  # 7.5 million
    "scan_requests": 500000,    # 500 thousand
  },
]

COMMON_OPTIONS = {
  "bg_threads": 4,
  "latency_sample_period": 10,

  # Affects RocksDB & LLSM
  "bypass_wal": True,
  "use_direct_io": True,

  # Affects RocksDB
  "rdb_bloom_bits": 10,
  "rdb_prefix_bloom_size": 3,

  # Affects LLSM
  "reorg_length": 2,
  "use_alex": False,
  "deferral_autotuning": True,
  "max_deferrals": 1,

  # Temporary: Disable batching when evicting from the cache.
  "rec_cache_batch_writeout": False,

  # Affects LLSM and page-grouped LLSM
  "optimistic_rec_caching": False,
}

SYNTH_DATASET = {
  "name": "synth",
  "multiplier": 1,
  "range_min": 0,
  "range_max": 2000000000,
}

CUSTOM_DATASETS = [
  {
    "name": "osm",
    "path": "'$TP_DATASET_PATH/osm_ny.txt'",
    # The dataset is this many times larger than the standard 20 M synthetic
    # dataset we use.
    "multiplier": 1.160804,
    "range_min": 699540,
    "range_max": 6820987374,
  },
  {
    "name": "amzn",
    "path": "'$TP_DATASET_PATH/amazon_reviews.txt'",
    # The dataset is this many times larger than the standard 20 M synthetic
    # dataset we use.
    "multiplier": 1.674881,
    "range_min": 10001,
    "range_max": 53096592,
  },
]

# Number of uniform updates to make during the preload process. The purpose of
# these updates is to ensure that RocksDB has sstables present in multiple
# levels.
NUM_PRELOAD_UPDATES = 40000000


###
### Utilities.
###

def process_config(db, config, dataset, workload=None):
  copy = config.copy()
  del copy["cache_mib"]
  del copy["memtable_mib"]
  del copy["name"]
  del copy["point_requests"]
  del copy["scan_requests"]

  # Set the memory configuration.
  if db == "pg_llsm":
    copy["cache_size_mib"] = int(dataset["multiplier"] * (
      config["cache_mib"] + (2 * config["memtable_mib"])
    ))
  else:
    copy["cache_size_mib"] = int(dataset["multiplier"] * config["cache_mib"])
    copy["memtable_size_mib"] = int(dataset["multiplier"] * config["memtable_mib"])

  # Set the arguments used to customize the workload.
  if workload is not None and (workload == "e" or workload == "scan_only"):
    copy["gen_num_requests"] = int(dataset["multiplier"] * config["scan_requests"])
  else:
    copy["gen_num_requests"] = int(dataset["multiplier"] * config["point_requests"])

  # Sets the key range for inserts.
  copy["gen_range_min"] = dataset["range_min"]
  copy["gen_range_max"] = dataset["range_max"]

  # Enable parallel final flush when the workload does not contain inserts.
  # The workload is set to None when running a preload, which only has updates.
  if workload is None or (workload != "d" and workload != "e"):
    copy["pg_parallelize_final_flush"] = True

  return copy


###
### Get aggregated results.
###

run_command(
  name="combine-all",
  run="python3 combine_raw.py",
  deps=[
    ":synth",
    ":osm",
    ":amzn",
  ],
)

run_command(
  name="combine-main",
  run="python3 combine_raw.py",
  deps=[":main"],
)

run_command(
  name="combine-main-zipfian",
  run="python3 combine_raw.py",
  deps=[":main-zipfian"],
)

###
### YCSB.
###

ALL_EXPERIMENTS = [
  ":{}-{}-{}-{}-{}-{}".format(*zipped)
  for zipped in product(
    ["synth", "osm", "amzn"],
    DBS,
    ["64B", "1024B"],
    WORKLOADS,
    DISTRIBUTIONS,
    THREADS,
  )
  # The uniform and zipfian "d" workloads are the same, so just run one.
  if not (zipped[3] == "d" and zipped[4] == "uniform")
]

# "Main" tasks are the ones we prioritize.

MAIN = [
  exp_name
  for exp_name in ALL_EXPERIMENTS
  if ("amzn" in exp_name) or ("scan_only" in exp_name)
]

MAIN_ZIPFIAN = [
  exp_name for exp_name in MAIN if "zipfian" in exp_name
]

MAIN_PGLLSM = [
  exp_name for exp_name in MAIN if "pg_llsm" in exp_name
]

MAIN_PGLLSM_ZIPFIAN = [
  exp_name for exp_name in MAIN_PGLLSM if "zipfian" in exp_name
]

# All YCSB experiments.
combine(
  name="ycsb",
  deps=[
    ":synth",
    ":osm",
    ":amzn",
  ],
)

combine(name="main", deps=MAIN)
combine(name="main-zipfian", deps=MAIN_ZIPFIAN)
combine(name="main-pg_llsm", deps=MAIN_PGLLSM)
combine(name="main-pg_llsm-zipfian", deps=MAIN_PGLLSM_ZIPFIAN)

# The tasks below are used for dividing up the experiments across 2 machines.

group(
  name="ycsb-1-of-2",
  deps=[
    exp_name for exp_name in ALL_EXPERIMENTS if hash(exp_name) % 2 == 0
  ],
)

group(
  name="ycsb-2-of-2",
  deps=[
    exp_name for exp_name in ALL_EXPERIMENTS if hash(exp_name) % 2 == 1
  ],
)

group(
  name="main-1-of-2",
  deps=[
    exp_name for exp_name in MAIN if hash(exp_name) % 2 == 0
  ],
)

group(
  name="main_zipfian-1-of-2",
  deps=[
    exp_name for exp_name in MAIN_ZIPFIAN if hash(exp_name) % 2 == 0
  ],
)

group(
  name="main_pg_llsm_zipfian-1-of-2",
  deps=[
    exp_name for exp_name in MAIN_PGLLSM_ZIPFIAN if hash(exp_name) % 2 == 0
  ],
)

group(
  name="main-2-of-2",
  deps=[
    exp_name for exp_name in MAIN if hash(exp_name) % 2 == 1
  ],
)

group(
  name="main_zipfian-2-of-2",
  deps=[
    exp_name for exp_name in MAIN_ZIPFIAN if hash(exp_name) % 2 == 1
  ],
)

group(
  name="main_pg_llsm_zipfian-2-of-2",
  deps=[
    exp_name for exp_name in MAIN_PGLLSM_ZIPFIAN if hash(exp_name) % 2 == 1
  ],
)

###
### The actual YCSB experiment definitions.
###

run_experiment_group(
  name="synth",
  run="./run.sh",
  experiments=[
    # e.g. synth-pg_llsm-64B-a-zipfian-1
    ExperimentInstance(
      name="synth-{}-{}-{}-{}-{}".format(db, config["name"], workload, dist, threads),
      options={
        **COMMON_OPTIONS,
        **process_config(db, config, SYNTH_DATASET, workload=workload),
        "db": db,
        "checkpoint_name": "ycsb-synth-{}-{}".format(db, config["name"]),
        "threads": threads,
        "gen_template": "workloads/{}.yml".format(workload),
        "gen_distribution": dist,
      },
    )
    for db, config, workload, dist, threads in product(
      DBS,
      CONFIGS,
      WORKLOADS,
      DISTRIBUTIONS,
      THREADS,
    )
    # The uniform and zipfian "d" workloads are the same, so just run one.
    if not (workload == "d" and dist == "uniform")
  ],
  deps=[
    # e.g. :preload-synth-pg_llsm-64B
    ":preload-synth-{}-{}".format(db, config["name"])
    for db, config in product(DBS, CONFIGS)
  ],
)

for dataset in CUSTOM_DATASETS:
  # `amzn` and `osm`
  run_experiment_group(
    name="{}".format(dataset["name"]),
    run="./run.sh",
    experiments=[
      # e.g. amzn-pg_llsm-64B-a-zipfian-1
      ExperimentInstance(
        name="{}-{}-{}-{}-{}-{}".format(dataset["name"], db, config["name"], workload, dist, threads),
        options={
          **COMMON_OPTIONS,
          **process_config(db, config, dataset, workload=workload),
          "db": db,
          "checkpoint_name": "ycsb-{}-{}-{}".format(dataset["name"], db, config["name"]),
          "custom_dataset": dataset["path"],
          "threads": threads,
          "gen_template": "workloads/{}.yml".format(workload),
          "gen_distribution": dist,
        },
      )
      for db, config, workload, dist, threads in product(
        DBS,
        CONFIGS,
        WORKLOADS,
        DISTRIBUTIONS,
        THREADS,
      )
      # The uniform and zipfian "d" workloads are the same, so just run one.
      if not (workload == "d" and dist == "uniform")
    ],
    deps=[
      # e.g. :preload-amzn-pg_llsm-64B
      ":preload-{}-{}-{}".format(dataset["name"], db, config["name"])
      for db, config in product(DBS, CONFIGS)
    ],
  )


###
### Preload.
###

# Run all preload tasks.
group(
  name="preload",
  deps=[
    ":preload-{}-{}-{}".format(*zipped)
    for zipped in product(
      ["synth", "osm", "amzn"],
      DBS,
      map(lambda c: c["name"], CONFIGS),
    )
  ],
)

for db, config in product(DBS, CONFIGS):
  run_command(
    name="preload-synth-{}-{}".format(db, config["name"]),
    run="./preload.sh",
    options={
      **COMMON_OPTIONS,
      **process_config(db, config, SYNTH_DATASET),
      "db": db,
      "checkpoint_name": "ycsb-synth-{}-{}".format(db, config["name"]),
      "threads": 1,
      "gen_template": "workloads/setup.yml",
      # NOTE: This overrides any previously set value.
      "gen_num_requests": NUM_PRELOAD_UPDATES,
    },
  )

  for dataset in CUSTOM_DATASETS:
    run_command(
      name="preload-{}-{}-{}".format(dataset["name"], db, config["name"]),
      run="./preload.sh" ,
      options={
        **COMMON_OPTIONS,
        **process_config(db, config, dataset),
        "db": db,
        "checkpoint_name": "ycsb-{}-{}-{}".format(dataset["name"], db, config["name"]),
        "custom_dataset": dataset["path"],
        "threads": 1,
        "gen_template": "workloads/setup.yml",
        # NOTE: This overrides any previously set value.
        "gen_num_requests": NUM_PRELOAD_UPDATES,
      },
    )
