from itertools import product

ORDERING = ["order", "shuffle"]
RECORD_SIZES = [16, 512]
COMMON_OPTIONS = {
  "bg_threads": 16,
  "data_mib": 1024,
  "bypass_wal": True,
  "memtable_size_mib": 64,
  "cache_size_mib": 64,
  "tl_page_fill_pct": 50,
}
DEFER_OPTIONS = [
  {
    "record_size_bytes": 16,
    # 400 records x 16 bytes
    "io_min_batch_size": 6400,
    "max_deferrals": 2,
  },
  {
    "record_size_bytes": 512,
    # 100 records x 512 bytes
    "io_min_batch_size": 51200,
    "max_deferrals": 1,
  },
]

# These experiments are used to evaluate the performance of LLSM on a few
# preset "overall" configurations without deferred I/O.
run_experiment_group(
  name="llsm_no_deferral",
  run="./run_synth_write.sh",
  experiments=[
    ExperimentInstance(
      name="sw_{order}_{record_size}-llsm".format(
        order=order,
        record_size=record_size,
      ),
      options={
        **COMMON_OPTIONS,
        "db": "llsm",
        "record_size_bytes": record_size,
        "shuffle": True if order == "shuffle" else False,
      },
    )
    for order, record_size in product(ORDERING, RECORD_SIZES)
  ],
  deps=[
    "//scripts/e2e_perf:build_benchmarks",
  ],
)

# These experiments are used to evaluate the performance of LLSM on a few
# preset configurations when deferred I/O is used. We only use shuffled
# data in this experiment group.
run_experiment_group(
  name="llsm_deferral",
  run="./run_synth_write.sh",
  experiments=[
    ExperimentInstance(
      name="sw_shuffle_{record_size}_defer-llsm".format(
        record_size=instance_options["record_size_bytes"],
      ),
      options={
        **COMMON_OPTIONS,
        **instance_options,
        "db": "llsm",
        "shuffle": True,
      },
    )
    for instance_options in DEFER_OPTIONS
  ],
  deps=[
    "//scripts/e2e_perf:build_benchmarks",
  ],
)

# An alias task that runs both `:llsm_no_deferral` and `:llsm_deferral`.
group(
  name="llsm",
  deps=[
    ":llsm_no_deferral",
    # NOTE: We disabled llsm_deferral because it is too slow.
    #":llsm_deferral",
  ],
)

# These experiments are used to evaluate the performance of RocksDB on a few
# preset "overall" configurations.
run_experiment_group(
  name="rocksdb",
  run="./run_synth_write.sh",
  experiments=[
    ExperimentInstance(
      name="sw_{order}_{record_size}-rocksdb".format(
        order=order,
        record_size=record_size,
      ),
      options={
        **COMMON_OPTIONS,
        "db": "rocksdb",
        "record_size_bytes": record_size,
        "shuffle": True if order == "shuffle" else False,
      },
    )
    for order, record_size in product(ORDERING, RECORD_SIZES)
  ],
  deps=[
    "//scripts/e2e_perf:build_benchmarks",
  ],
)

# Aggregates the results from the tasks above into one CSV file.
run_command(
  name="summarize_overall",
  run="python3 summarize.py",
  deps=[
    ":llsm_no_deferral",
    # NOTE: We disabled llsm_deferral because it is too slow.
    #":llsm_deferral",
    ":rocksdb",
  ],
)
